{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12666460,"sourceType":"datasetVersion","datasetId":8004364}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Required Imports**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nimport os\nimport time\nimport copy\nfrom sklearn.metrics import confusion_matrix, precision_recall_fscore_support\nimport numpy as np\nfrom PIL import Image\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T07:35:38.672489Z","iopub.execute_input":"2025-08-04T07:35:38.672794Z","iopub.status.idle":"2025-08-04T07:35:48.827949Z","shell.execute_reply.started":"2025-08-04T07:35:38.672772Z","shell.execute_reply":"2025-08-04T07:35:48.827163Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## **Configuration**","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/my-mc-defect-dataset/my_defect_dataset' \n\nBATCH_SIZE = 32\nNUM_EPOCHS = 25 \nLEARNING_RATE = 0.001\nMODEL_SAVE_PATH = 'best_defect_classifier_multi_category.pth'\n\n# --- 1. Define Image Transformations ---\n# ImageNet statistics for normalization\nIMAGENET_MEAN = [0.485, 0.456, 0.406]\nIMAGENET_STD = [0.229, 0.224, 0.225]\n\n# Transformations for the training set (with data augmentation)\ntrain_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), # Random crop to 224x224, varying scale\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(15), # Rotate by +/- 15 degrees\n    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05), # Random color jitter\n    transforms.ToTensor(), # Convert PIL Image to PyTorch Tensor\n    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD) # Normalize pixels\n])\n\n# Transformations for the validation and test sets (no augmentation, only resizing and normalization)\nval_test_transforms = transforms.Compose([\n    transforms.Resize(256), # Resize to 256\n    transforms.CenterCrop(224), # Crop the center 224x224\n    transforms.ToTensor(),\n    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n])\n\n# --- 2. Create Dataset and DataLoader ---\nprint(\"Loading datasets...\")\n\n# Create dictionaries to hold datasets and dataloaders\nimage_datasets = {\n    'train': datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), train_transforms),\n    'val': datasets.ImageFolder(os.path.join(DATA_DIR, 'val'), val_test_transforms),\n    'test': datasets.ImageFolder(os.path.join(DATA_DIR, 'test'), val_test_transforms)\n}\n\ndataloaders = {\n    'train': DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True, num_workers=4),\n    'val': DataLoader(image_datasets['val'], batch_size=BATCH_SIZE, shuffle=False, num_workers=4),\n    'test': DataLoader(image_datasets['test'], batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\nclass_names = image_datasets['train'].classes # This will be ['defective_product', 'good_product'] or vice versa\nnum_classes = len(class_names)\n\nprint(f\"Dataset sizes: {dataset_sizes}\")\nprint(f\"Class names: {class_names}\")\n\n# Map class names to their numerical labels (e.g., 'good_product': 0, 'defective_product': 1)\nclass_to_idx = image_datasets['train'].class_to_idx\nprint(f\"Class to index mapping: {class_to_idx}\")\n\n# --- 3. Define Model Architecture (Transfer Learning) ---\nprint(\"\\nSetting up model...\")\n\n# Use GPU if available, else CPU\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load a pre-trained ResNet50 model\n# We use ResNet50_Weights.IMAGENET1K_V1 for consistency with common practices\nmodel = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n\n# Freeze all parameters in the pre-trained model (optional, but good for initial training)\n# This means only the final layer's weights will be updated\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Get the number of in_features for the last fully connected layer\nnum_ftrs = model.fc.in_features\n# Replace the classifier head with a new one for our 2 classes\nmodel.fc = nn.Linear(num_ftrs, num_classes)\n\n# Move the model to the selected device (GPU or CPU)\nmodel = model.to(device)\n\n# --- 4. Set up Loss Function and Optimizer ---\n# CrossEntropyLoss automatically handles softmax and NLLLoss internally\ncriterion = nn.CrossEntropyLoss()\n\n# Only optimize the parameters of the new (unfrozen) final layer\noptimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE)\n\nprint(\"Setup complete. Ready for training.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T07:37:52.529443Z","iopub.execute_input":"2025-08-04T07:37:52.529785Z","iopub.status.idle":"2025-08-04T07:37:56.170534Z","shell.execute_reply.started":"2025-08-04T07:37:52.529754Z","shell.execute_reply":"2025-08-04T07:37:56.169778Z"}},"outputs":[{"name":"stdout","text":"Loading datasets...\nDataset sizes: {'train': 405, 'val': 276, 'test': 84}\nClass names: ['defective_product', 'good_product']\nClass to index mapping: {'defective_product': 0, 'good_product': 1}\n\nSetting up model...\nUsing device: cuda:0\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 177MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Setup complete. Ready for training.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## **Training and Validation**","metadata":{}},{"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=NUM_EPOCHS):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                # Track history only in train phase\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # Backward + optimize only in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            # Deep copy the model if it's the best validation accuracy\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n        \n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n\n    # Load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\n# Call the training function\nmodel_ft = train_model(model, dataloaders, criterion, optimizer, num_epochs=NUM_EPOCHS)\n\n# Save the best model\ntorch.save(model_ft.state_dict(), MODEL_SAVE_PATH)\nprint(f\"Model saved to: {MODEL_SAVE_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T07:40:18.856644Z","iopub.execute_input":"2025-08-04T07:40:18.856938Z","iopub.status.idle":"2025-08-04T07:45:21.432719Z","shell.execute_reply.started":"2025-08-04T07:40:18.856916Z","shell.execute_reply":"2025-08-04T07:45:21.431847Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/25\n----------\ntrain Loss: 0.3204 Acc: 0.8864\nval Loss: 0.3967 Acc: 0.9022\n\nEpoch 2/25\n----------\ntrain Loss: 0.2426 Acc: 0.9333\nval Loss: 0.3880 Acc: 0.9022\n\nEpoch 3/25\n----------\ntrain Loss: 0.2411 Acc: 0.9333\nval Loss: 0.3451 Acc: 0.9022\n\nEpoch 4/25\n----------\ntrain Loss: 0.2268 Acc: 0.9333\nval Loss: 0.3111 Acc: 0.9022\n\nEpoch 5/25\n----------\ntrain Loss: 0.2308 Acc: 0.9333\nval Loss: 0.3244 Acc: 0.9022\n\nEpoch 6/25\n----------\ntrain Loss: 0.2264 Acc: 0.9333\nval Loss: 0.3338 Acc: 0.9022\n\nEpoch 7/25\n----------\ntrain Loss: 0.1973 Acc: 0.9333\nval Loss: 0.3286 Acc: 0.9022\n\nEpoch 8/25\n----------\ntrain Loss: 0.2016 Acc: 0.9358\nval Loss: 0.3055 Acc: 0.9022\n\nEpoch 9/25\n----------\ntrain Loss: 0.1984 Acc: 0.9333\nval Loss: 0.2954 Acc: 0.9058\n\nEpoch 10/25\n----------\ntrain Loss: 0.2088 Acc: 0.9284\nval Loss: 0.3441 Acc: 0.8913\n\nEpoch 11/25\n----------\ntrain Loss: 0.2259 Acc: 0.9333\nval Loss: 0.3249 Acc: 0.9094\n\nEpoch 12/25\n----------\ntrain Loss: 0.1963 Acc: 0.9309\nval Loss: 0.2989 Acc: 0.9022\n\nEpoch 13/25\n----------\ntrain Loss: 0.1663 Acc: 0.9481\nval Loss: 0.3043 Acc: 0.9058\n\nEpoch 14/25\n----------\ntrain Loss: 0.1830 Acc: 0.9333\nval Loss: 0.2961 Acc: 0.9058\n\nEpoch 15/25\n----------\ntrain Loss: 0.1728 Acc: 0.9407\nval Loss: 0.3417 Acc: 0.9022\n\nEpoch 16/25\n----------\ntrain Loss: 0.2216 Acc: 0.9333\nval Loss: 0.3117 Acc: 0.8986\n\nEpoch 17/25\n----------\ntrain Loss: 0.1923 Acc: 0.9383\nval Loss: 0.3154 Acc: 0.8986\n\nEpoch 18/25\n----------\ntrain Loss: 0.1796 Acc: 0.9407\nval Loss: 0.2893 Acc: 0.9022\n\nEpoch 19/25\n----------\ntrain Loss: 0.1832 Acc: 0.9457\nval Loss: 0.2924 Acc: 0.9058\n\nEpoch 20/25\n----------\ntrain Loss: 0.1688 Acc: 0.9407\nval Loss: 0.3038 Acc: 0.9130\n\nEpoch 21/25\n----------\ntrain Loss: 0.1843 Acc: 0.9333\nval Loss: 0.3215 Acc: 0.9058\n\nEpoch 22/25\n----------\ntrain Loss: 0.2104 Acc: 0.9358\nval Loss: 0.4013 Acc: 0.8080\n\nEpoch 23/25\n----------\ntrain Loss: 0.2126 Acc: 0.9358\nval Loss: 0.2867 Acc: 0.9058\n\nEpoch 24/25\n----------\ntrain Loss: 0.1618 Acc: 0.9457\nval Loss: 0.3008 Acc: 0.9058\n\nEpoch 25/25\n----------\ntrain Loss: 0.1889 Acc: 0.9383\nval Loss: 0.3096 Acc: 0.9130\n\nTraining complete in 5m 2s\nBest val Acc: 0.913043\nModel saved to: best_defect_classifier_multi_category.pth\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## **Model Evaluation**","metadata":{}},{"cell_type":"code","source":"# Define the model architecture again to load weights into it\nmodel_ft_eval = models.resnet50(weights=None) # No pre-trained weights needed here\nnum_ftrs = model_ft_eval.fc.in_features\nmodel_ft_eval.fc = nn.Linear(num_ftrs, num_classes)\n\n# Load the saved best weights\nmodel_ft_eval.load_state_dict(torch.load(MODEL_SAVE_PATH))\nmodel_ft_eval = model_ft_eval.to(device)\n\ndef evaluate_model(model, dataloader, class_names):\n    model.eval()  # Set model to evaluation mode\n    all_preds = []\n    all_labels = []\n\n    print(\"\\nStarting final evaluation on test set...\")\n    with torch.no_grad():\n        for inputs, labels in dataloader['test']:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Calculate metrics\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    # Precision, Recall, F1-score per class\n    precision, recall, f1_score, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.arange(len(class_names)))\n    \n    print(\"\\n--- Evaluation Results on Test Set ---\")\n    print(\"Confusion Matrix:\")\n    print(cm)\n    \n    print(\"\\nMetrics per class:\")\n    for i, class_name in enumerate(class_names):\n        print(f\"Class: {class_name}\")\n        print(f\"  Precision: {precision[i]:.4f}\")\n        print(f\"  Recall:    {recall[i]:.4f}\")\n        print(f\"  F1-score:  {f1_score[i]:.4f}\")\n\n    # Overall accuracy\n    overall_accuracy = np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n    print(f\"\\nOverall Test Accuracy: {overall_accuracy:.4f}\")\n\n# Call the evaluation function on the best model\nevaluate_model(model_ft_eval, dataloaders, class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T07:48:01.782925Z","iopub.execute_input":"2025-08-04T07:48:01.783299Z","iopub.status.idle":"2025-08-04T07:48:05.035728Z","shell.execute_reply.started":"2025-08-04T07:48:01.783265Z","shell.execute_reply":"2025-08-04T07:48:05.034788Z"}},"outputs":[{"name":"stdout","text":"\nStarting final evaluation on test set...\n\n--- Evaluation Results on Test Set ---\nConfusion Matrix:\n[[ 0 24]\n [ 0 60]]\n\nMetrics per class:\nClass: defective_product\n  Precision: 0.0000\n  Recall:    0.0000\n  F1-score:  0.0000\nClass: good_product\n  Precision: 0.7143\n  Recall:    1.0000\n  F1-score:  0.8333\n\nOverall Test Accuracy: 0.7143\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## **Model Retraining**","metadata":{}},{"cell_type":"code","source":"print(\"Recalculating weights for imbalanced classes...\")\n\n# Calculate class weights\n# We can use the train dataset to get a representative count\ntrain_counts = [0] * num_classes\nfor _, label in dataloaders['train'].dataset.samples:\n    train_counts[label] += 1\n\ntotal_samples = sum(train_counts)\nclass_weights = total_samples / torch.Tensor(train_counts)\n\n# Invert the weights for CrossEntropyLoss (higher weight for smaller class)\n# Let's say defective_product is index 0 and good_product is index 1\n# This ensures that the loss for a defective product is penalized more\nclass_weights = class_weights.to(device)\n\nprint(f\"Original class counts: {train_counts}\")\nprint(f\"Calculated class weights: {class_weights}\")\n\n# Use weighted CrossEntropyLoss\ncriterion_weighted = nn.CrossEntropyLoss(weight=class_weights)\n\n# --- Fine-tuning the entire network ---\nprint(\"\\nUnfreezing all layers for fine-tuning...\")\n\n# Unfreeze all model parameters\nfor param in model.parameters():\n    param.requires_grad = True\n\n# Now, we will optimize ALL parameters, but with a much lower learning rate\n# This helps prevent catastrophic forgetting of the pre-trained weights\noptimizer_fine_tune = optim.Adam(model.parameters(), lr=0.0001)\n\n# --- Re-run the Training Loop with the new setup ---\n\nprint(\"\\nStarting fine-tuning...\")\nNUM_EPOCHS_FINE_TUNE = 15 # Train for fewer epochs now\nmodel_ft_tuned = train_model(model, dataloaders, criterion_weighted, optimizer_fine_tune, num_epochs=NUM_EPOCHS_FINE_TUNE)\n\n# Save the newly fine-tuned model\ntorch.save(model_ft_tuned.state_dict(), 'best_fine_tuned_classifier.pth')\nprint(f\"Fine-tuned model saved to: best_fine_tuned_classifier.pth\")\n\n# --- Final Evaluation on the Fine-Tuned Model ---\n\n# We need to reload the model with the best fine-tuned weights\nmodel_ft_tuned.load_state_dict(torch.load('best_fine_tuned_classifier.pth'))\n\n# Run the evaluation function\nevaluate_model(model_ft_tuned, dataloaders, class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T07:50:26.833966Z","iopub.execute_input":"2025-08-04T07:50:26.834836Z","iopub.status.idle":"2025-08-04T07:53:53.053587Z","shell.execute_reply.started":"2025-08-04T07:50:26.834800Z","shell.execute_reply":"2025-08-04T07:53:53.052636Z"}},"outputs":[{"name":"stdout","text":"Recalculating weights for imbalanced classes...\nOriginal class counts: [27, 378]\nCalculated class weights: tensor([15.0000,  1.0714], device='cuda:0')\n\nUnfreezing all layers for fine-tuning...\n\nStarting fine-tuning...\nEpoch 1/15\n----------\ntrain Loss: 1.0597 Acc: 0.7457\nval Loss: 0.7887 Acc: 0.7065\n\nEpoch 2/15\n----------\ntrain Loss: 0.5778 Acc: 0.6840\nval Loss: 0.5341 Acc: 0.7464\n\nEpoch 3/15\n----------\ntrain Loss: 0.4736 Acc: 0.7062\nval Loss: 0.5717 Acc: 0.7609\n\nEpoch 4/15\n----------\ntrain Loss: 0.4321 Acc: 0.7481\nval Loss: 0.4921 Acc: 0.8043\n\nEpoch 5/15\n----------\ntrain Loss: 0.3811 Acc: 0.7012\nval Loss: 0.5532 Acc: 0.7500\n\nEpoch 6/15\n----------\ntrain Loss: 0.4765 Acc: 0.8543\nval Loss: 0.5260 Acc: 0.7101\n\nEpoch 7/15\n----------\ntrain Loss: 0.3335 Acc: 0.7333\nval Loss: 0.5836 Acc: 0.7428\n\nEpoch 8/15\n----------\ntrain Loss: 0.3823 Acc: 0.8173\nval Loss: 0.6543 Acc: 0.6993\n\nEpoch 9/15\n----------\ntrain Loss: 0.3950 Acc: 0.8370\nval Loss: 0.7962 Acc: 0.6775\n\nEpoch 10/15\n----------\ntrain Loss: 0.2626 Acc: 0.8988\nval Loss: 0.4145 Acc: 0.8370\n\nEpoch 11/15\n----------\ntrain Loss: 0.2525 Acc: 0.8815\nval Loss: 0.7152 Acc: 0.8007\n\nEpoch 12/15\n----------\ntrain Loss: 0.2782 Acc: 0.8568\nval Loss: 0.4970 Acc: 0.8116\n\nEpoch 13/15\n----------\ntrain Loss: 0.2807 Acc: 0.9185\nval Loss: 0.5823 Acc: 0.8261\n\nEpoch 14/15\n----------\ntrain Loss: 0.2793 Acc: 0.8543\nval Loss: 0.4319 Acc: 0.7935\n\nEpoch 15/15\n----------\ntrain Loss: 0.2142 Acc: 0.9136\nval Loss: 0.3990 Acc: 0.8514\n\nTraining complete in 3m 23s\nBest val Acc: 0.851449\nFine-tuned model saved to: best_fine_tuned_classifier.pth\n\nStarting final evaluation on test set...\n\n--- Evaluation Results on Test Set ---\nConfusion Matrix:\n[[13 11]\n [ 7 53]]\n\nMetrics per class:\nClass: defective_product\n  Precision: 0.6500\n  Recall:    0.5417\n  F1-score:  0.5909\nClass: good_product\n  Precision: 0.8281\n  Recall:    0.8833\n  F1-score:  0.8548\n\nOverall Test Accuracy: 0.7857\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## **Model Testing**","metadata":{}},{"cell_type":"code","source":"# Path to a sample image from your test set (e.g., a defective product)\nsample_image_path = '/kaggle/input/my-mc-defect-dataset/my_defect_dataset/test/defective_product/000.png' \n\n# Load the saved model\nloaded_model = models.resnet50(weights=None)\nnum_ftrs = loaded_model.fc.in_features\nloaded_model.fc = nn.Linear(num_ftrs, num_classes)\nloaded_model.load_state_dict(torch.load('best_fine_tuned_classifier.pth'))\nloaded_model = loaded_model.to(device)\nloaded_model.eval()\n\n# The same transformations used for the test set must be applied to new images\ninference_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n])\n\ndef predict_image(image_path, model, transform, class_names):\n    \"\"\"\n    Predicts the class of a single image.\n    \n    Args:\n        image_path (str): The path to the image file.\n        model (nn.Module): The trained model.\n        transform (transforms.Compose): The image transformations.\n        class_names (list): The list of class names.\n    \n    Returns:\n        tuple: The predicted class name and confidence score.\n    \"\"\"\n    # Load the image\n    image = Image.open(image_path).convert('RGB')\n    \n    # Apply transformations and add a batch dimension\n    image_tensor = transform(image).unsqueeze(0).to(device)\n    \n    # Make a prediction\n    with torch.no_grad():\n        output = model(image_tensor)\n        \n    # Get the confidence score and predicted class\n    probabilities = F.softmax(output, dim=1)\n    confidence, predicted_idx = torch.max(probabilities, 1)\n    predicted_class = class_names[predicted_idx.item()]\n    \n    return predicted_class, confidence.item()\n\n# Run the prediction on the sample image\npredicted_class, confidence = predict_image(sample_image_path, loaded_model, inference_transforms, class_names)\n\nprint(f\"Sample Image Path: {sample_image_path}\")\nprint(f\"Predicted Class: {predicted_class}\")\nprint(f\"Confidence: {confidence:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T08:00:25.351687Z","iopub.execute_input":"2025-08-04T08:00:25.352018Z","iopub.status.idle":"2025-08-04T08:00:26.044384Z","shell.execute_reply.started":"2025-08-04T08:00:25.351991Z","shell.execute_reply":"2025-08-04T08:00:26.043615Z"}},"outputs":[{"name":"stdout","text":"Sample Image Path: /kaggle/input/my-mc-defect-dataset/my_defect_dataset/test/defective_product/000.png\nPredicted Class: good_product\nConfidence: 0.8028\n","output_type":"stream"}],"execution_count":13}]}